{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77936b7b-f520-4306-a0fa-d5c5067002f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av  \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b13c178-b7f2-4267-84eb-82405a185b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755018587.987301 2157816 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1755018587.999324 2334317 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755018588.005183 2334317 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755018588.079280 2334314 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected FPS from PyAV: 30.0\n",
      "-------- Detection Report --------\n",
      "Total frames: 3233\n",
      "Frames with at least 1 hand detected: 2701\n",
      "Detection rate: 83.54%\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n",
    "\n",
    "container = av.open(\"test6-2.mov\")\n",
    "stream = container.streams.video[0]\n",
    "fps = float(stream.average_rate) if stream.average_rate else 30  \n",
    "print(f\"Detected FPS from PyAV: {fps}\")\n",
    "\n",
    "width = stream.codec_context.width\n",
    "height = stream.codec_context.height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "out = cv2.VideoWriter(\"output_with_hands_colored_VFR.mov\", fourcc, fps, (width, height))\n",
    "\n",
    "landmark_csv = open(\"test6-2.csv\", mode=\"w\", newline=\"\")\n",
    "landmark_writer = csv.writer(landmark_csv)\n",
    "landmark_writer.writerow([\"frame\", \"time_sec\", \"hand\", \"landmark_id\", \"x\", \"y\", \"z\", \"hand_detected\"])\n",
    "\n",
    "summary_csv = open(\"frame_detection_summary.csv\", mode=\"w\", newline=\"\")\n",
    "summary_writer = csv.writer(summary_csv)\n",
    "summary_writer.writerow([\"frame\", \"time_sec\", \"hands_detected\", \"hand_labels_detected\"])\n",
    "\n",
    "frame_num = 0\n",
    "frames_with_detection = 0\n",
    "total_frames = 0\n",
    "\n",
    "for frame in container.decode(video=0):\n",
    "    # PyAV frame -> numpy array (RGB)\n",
    "    img = frame.to_ndarray(format=\"bgr24\")\n",
    "    time_sec = float(frame.pts * frame.time_base) if frame.pts else frame_num / fps\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img_rgb)\n",
    "\n",
    "    detected_labels = []\n",
    "\n",
    "    if result.multi_hand_landmarks and result.multi_handedness:\n",
    "        hands_detected = len(result.multi_hand_landmarks)\n",
    "        frames_with_detection += 1\n",
    "\n",
    "        for (hand_landmarks, handedness) in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "            hand_label = handedness.classification[0].label  # 'Left' or 'Right'\n",
    "            detected_labels.append(hand_label)\n",
    "\n",
    "            for idx, lm in enumerate(hand_landmarks.landmark):\n",
    "                landmark_writer.writerow([frame_num, time_sec, hand_label, idx, lm.x, lm.y, lm.z, 1])\n",
    "\n",
    "            # Draw with different color\n",
    "            color = (0, 255, 0) if hand_label == \"Left\" else (0, 0, 255)\n",
    "            mp_draw.draw_landmarks(\n",
    "                img, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_draw.DrawingSpec(color=color, thickness=2, circle_radius=3),\n",
    "                mp_draw.DrawingSpec(color=color, thickness=2)\n",
    "            )\n",
    "    else:\n",
    "        hands_detected = 0\n",
    "        for hand_label in ['Left', 'Right']:\n",
    "            for idx in range(21):\n",
    "                landmark_writer.writerow([frame_num, time_sec, hand_label, idx, None, None, None, 0])\n",
    "\n",
    "    summary_writer.writerow([frame_num, time_sec, hands_detected, ','.join(detected_labels)])\n",
    "\n",
    "    out.write(img)\n",
    "\n",
    "    cv2.imshow(\"Hand Detection VFR\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_num += 1\n",
    "    total_frames += 1\n",
    "\n",
    "landmark_csv.close()\n",
    "summary_csv.close()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"-------- Detection Report --------\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Frames with at least 1 hand detected: {frames_with_detection}\")\n",
    "print(f\"Detection rate: {frames_with_detection/total_frames:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea209142-4798-4ba1-87cb-d856ee65a161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
